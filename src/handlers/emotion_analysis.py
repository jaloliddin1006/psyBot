#!/usr/bin/env python3
"""
Emotion Analysis Handlers for PsyBot
Provides analytics and insights about user's emotional patterns
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
from collections import Counter
import os
import tempfile
from aiogram import types, F, Router
from aiogram.fsm.context import FSMContext
from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup, FSInputFile
from aiogram.filters import StateFilter
from database.session import get_session, close_session
from database.models import User, EmotionEntry, WeeklyReflection
from .utils import delete_previous_messages
from constants import EMOTION_ANALYSIS_PERIOD_SELECTION, MAIN_MENU
from google import genai
import asyncio
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image as RLImage
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import urllib.request
from trial_manager import require_trial_access
from dotenv import load_dotenv
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.dates as mdates
import numpy as np
from PIL import Image as PILImage  # For reading chart dimensions

# Initialize logger and router
logger = logging.getLogger(__name__)
router = Router(name=__name__)

client = genai.Client(
    api_key=os.environ.get("GOOGLE_GENAI_API_KEY"),
    http_options={"base_url": os.environ.get("API_URL")}
)

# Emotion mapping for better readability
EMOTION_MAPPING = {
    "good_state_1": "–ü–æ–¥—ä–µ–º, –ª–µ–≥–∫–æ—Å—Ç—å",
    "good_state_2": "–°–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ, —Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–Ω–æ—Å—Ç—å", 
    "good_state_3": "–£—é—Ç, –±–ª–∏–∑–æ—Å—Ç—å",
    "good_state_4": "–ò–Ω—Ç–µ—Ä–µ—Å, –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ",
    "good_state_5": "–°–∏–ª–∞, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å",
    "bad_state_1": "–¢—è–∂–µ—Å—Ç—å, —É—Å—Ç–∞–ª–æ—Å—Ç—å",
    "bad_state_2": "–¢—Ä–µ–≤–æ–≥–∞, –±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ",
    "bad_state_3": "–ó–ª–æ—Å—Ç—å, —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ",
    "bad_state_4": "–û—Ç—Å—Ç—Ä–∞–Ω–µ–Ω–Ω–æ—Å—Ç—å, –æ–±–∏–¥–∞",
    "bad_state_5": "–í–∏–Ω–∞, —Å–º—É—â–µ–Ω–∏–µ"
}

OPTION_MAPPING = {
    "good_state_1": {0: "–ü—Ä–∏—è—Ç–Ω–æ", 1: "–ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç"},
    "good_state_2": {0: "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ", 1: "–ì–ª—É–±–æ–∫–∏–π –ø–æ–∫–æ–π"},
    "good_state_3": {0: "–¢–µ–ø–ª–æ", 1: "–ë–ª–∏–∑–æ—Å—Ç—å"},
    "good_state_4": {0: "–ò–Ω—Ç–µ—Ä–µ—Å", 1: "–í–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ"},
    "good_state_5": {0: "–°–∏–ª–∞", 1: "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"},
    "bad_state_1": {0: "–£—Å—Ç–∞–ª–æ—Å—Ç—å", 1: "–ü–æ—Ç–µ—Ä—è —Å–∏–ª"},
    "bad_state_2": {0: "–¢—Ä–µ–≤–æ–≥–∞", 1: "–ù–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"},
    "bad_state_3": {0: "–ó–ª–æ—Å—Ç—å", 1: "–†–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ"},
    "bad_state_4": {0: "–û—Ç—Å—Ç—Ä–∞–Ω–µ–Ω–Ω–æ—Å—Ç—å", 1: "–û–±–∏–¥–∞"},
    "bad_state_5": {0: "–í–∏–Ω–∞", 1: "–°–º—É—â–µ–Ω–∏–µ"}
}

async def start_emotion_analysis(message: types.Message, state: FSMContext):
    """Start emotion analysis flow"""
    logger.info(f"start_emotion_analysis invoked. message.from_user.id: {message.from_user.id}")
    
    session = get_session()
    db_user = session.query(User).filter(User.telegram_id == message.from_user.id).first()
    
    if not db_user or not getattr(db_user, 'registration_complete', False) or not db_user.full_name:
        close_session(session)
        await state.clear()
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≤–µ—Ä—à–∏—Ç–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é —Å –ø–æ–º–æ—â—å—é /start –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —ç–º–æ—Ü–∏–π.")
        return MAIN_MENU
    
    close_session(session)
    
    # Check if user has any emotion entries
    session = get_session()
    emotion_count = session.query(EmotionEntry).filter(EmotionEntry.user_id == db_user.id).count()
    close_session(session)
    
    if emotion_count == 0:
        await message.answer("–£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ —ç–º–æ—Ü–∏–π. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Å–≤–æ–∏ —ç–º–æ—Ü–∏–∏, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É!")
        return MAIN_MENU
    
    # Store message for deletion
    data = await state.get_data()
    messages_to_delete = data.get('messages_to_delete', [])
    messages_to_delete.append(message.message_id)
    await state.update_data(messages_to_delete=messages_to_delete)
    
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="3 –¥–Ω—è", callback_data="period_3")],
        [InlineKeyboardButton(text="–ù–µ–¥–µ–ª—è (7 –¥–Ω–µ–π)", callback_data="period_7")],
        [InlineKeyboardButton(text="–î–≤–µ –Ω–µ–¥–µ–ª–∏ (14 –¥–Ω–µ–π)", callback_data="period_14")],
        [InlineKeyboardButton(text="–ú–µ—Å—è—Ü (30 –¥–Ω–µ–π)", callback_data="period_30")],
        [InlineKeyboardButton(text="3 –º–µ—Å—è—Ü–∞ (90 –¥–Ω–µ–π)", callback_data="period_90")],
        [InlineKeyboardButton(text="–ù–∞–∑–∞–¥", callback_data="back_to_main")]
    ])
    
    sent = await message.answer("–ö–∞–∫–æ–π –ø–µ—Ä–∏–æ–¥ —Ç–µ–±—è –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç?", reply_markup=keyboard)
    messages_to_delete.append(sent.message_id)
    await state.update_data(messages_to_delete=messages_to_delete)
    await state.set_state(EMOTION_ANALYSIS_PERIOD_SELECTION)
    
    return EMOTION_ANALYSIS_PERIOD_SELECTION

@router.callback_query(F.data == "back_to_main")
@require_trial_access('emotion_analytics')
async def handle_back_to_main_from_analysis(callback: types.CallbackQuery, state: FSMContext):
    """Handle back to main menu from emotion analysis results"""
    await callback.answer()
    from handlers.main_menu import main_menu
    await delete_previous_messages(callback.message, state)
    await state.clear()
    await main_menu(callback, state)

@router.callback_query(StateFilter(EMOTION_ANALYSIS_PERIOD_SELECTION))
@require_trial_access('emotion_analytics')
async def handle_period_selection(callback: types.CallbackQuery, state: FSMContext):
    """Handle period selection for emotion analysis"""
    logger.info(f"handle_period_selection called with data: {callback.data}")
    await callback.answer()
    
    if callback.data == "back_to_main":
        from handlers.main_menu import main_menu
        await delete_previous_messages(callback.message, state)
        await state.clear()
        await main_menu(callback, state)
        return MAIN_MENU
    
    # Extract period days
    period_days = int(callback.data.split("_")[1])
    
    session = get_session()
    db_user = session.query(User).filter(User.telegram_id == callback.from_user.id).first()
    
    if not db_user:
        close_session(session)
        await callback.message.answer("–û—à–∏–±–∫–∞: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return MAIN_MENU
    
    # Get emotion entries for the period
    end_date = datetime.now()
    start_date = end_date - timedelta(days=period_days)
    
    emotion_entries = session.query(EmotionEntry).filter(
        EmotionEntry.user_id == db_user.id,
        EmotionEntry.created_at >= start_date,
        EmotionEntry.created_at <= end_date
    ).order_by(EmotionEntry.created_at.desc()).all()
    
    close_session(session)
    
    if not emotion_entries:
        await callback.message.edit_text(f"–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {period_days} –¥–Ω–µ–π –∑–∞–ø–∏—Å–µ–π –≤ –¥–Ω–µ–≤–Ω–∏–∫–µ —ç–º–æ—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        await delete_previous_messages(callback.message, state, keep_current=True)
        await state.clear()
        from handlers.main_menu import main_menu
        await main_menu(callback, state)
        return MAIN_MENU
    
    if period_days == 3:
        # Generate short text analysis for 3 days
        await generate_short_analysis(callback, state, emotion_entries, period_days)
    else:
        # Generate PDF report for longer periods
        await generate_pdf_report(callback, state, emotion_entries, period_days)
    
    # Don't immediately return to main menu - let the analysis functions handle the flow
    return

async def generate_short_analysis(callback: types.CallbackQuery, state: FSMContext, 
                                emotion_entries: List[EmotionEntry], period_days: int):
    """Generate short text analysis for 3 days"""
    
    # Analyze emotions
    emotion_states = [entry.state for entry in emotion_entries if entry.state]
    emotion_counter = Counter(emotion_states)
    most_common_emotion = emotion_counter.most_common(1)[0] if emotion_counter else None
    
    # Group entries by day
    daily_emotions = {}
    for entry in emotion_entries:
        day = entry.created_at.date()
        if day not in daily_emotions:
            daily_emotions[day] = []
        daily_emotions[day].append(entry)
    
    # Build analysis text
    start_date = (datetime.now() - timedelta(days=period_days)).strftime("%d.%m.%Y")
    end_date = datetime.now().strftime("%d.%m.%Y")
    
    analysis_text = f"üìä **–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –∑–∞ –ø–µ—Ä–∏–æ–¥ {start_date} - {end_date}**\n\n"
    
    if most_common_emotion:
        emotion_name = EMOTION_MAPPING.get(most_common_emotion[0], most_common_emotion[0])
        analysis_text += f"üéØ **–°–∞–º–∞—è —á–∞—Å—Ç–æ –∏—Å–ø—ã—Ç—ã–≤–∞–µ–º–∞—è —ç–º–æ—Ü–∏—è –∑–∞ 3 –¥–Ω—è:** {emotion_name}\n\n"
    
    # Key moments analysis section
    analysis_text += "üìù **–ö—Ä–∞—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤:**\n"
    
    # Sort all entries chronologically
    all_entries = sorted(emotion_entries, key=lambda x: x.created_at)
    
    # Separate entries into those with detailed context and simple diary entries
    entries_with_context = []
    simple_diary_entries = []
    
    for entry in all_entries:
        if entry.answer_text and entry.answer_text.strip():
            if entry.answer_text == "Emotion recorded from diary":
                # This is a simple emotion diary entry without detailed context
                simple_diary_entries.append(entry)
            elif entry.answer_text.startswith("Marked for therapy work:") or entry.answer_text.startswith("–û—Ç–º–µ—á–µ–Ω–æ –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏ —Å —Ç–µ—Ä–∞–ø–µ–≤—Ç–æ–º"):
                # This is marked for therapy work but might have context
                entries_with_context.append(entry)
            elif entry.answer_text.startswith("AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ–º–æ–≥–ª–∞"):
                therapy_marker = " [AI –ø–æ–º–æ–≥]"
                if ":" in entry.answer_text:
                    context = entry.answer_text.split(":", 1)[1].strip()
                entries_with_context.append(entry)
            elif entry.answer_text not in ["Marked for therapy work:"]:
                # This has actual user context/dialog
                entries_with_context.append(entry)
    
    # Show entries with detailed context first
    if entries_with_context:
        analysis_text += "**–ü–æ–¥—Ä–æ–±–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:**\n"
        for entry in entries_with_context:
            # Format date and time
            date_str = entry.created_at.strftime("%d.%m.%Y, %H:%M")
            
            # Get emotion name
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state) if entry.state else "—ç–º–æ—Ü–∏—è"
            
            # Get context/reason
            context = entry.answer_text.strip()
            
            # Handle special cases for marked therapy work
            therapy_marker = ""
            if context.startswith("Marked for therapy work:"):
                therapy_marker = " [–¥–ª—è —Ç–µ—Ä–∞–ø–∏–∏]"
                context = context.replace("Marked for therapy work:", "").strip()
                if context.startswith("Marked for work (text not found in FSM)"):
                    continue  # Skip entries without proper context
            elif context.startswith("–û—Ç–º–µ—á–µ–Ω–æ –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏ —Å —Ç–µ—Ä–∞–ø–µ–≤—Ç–æ–º"):
                therapy_marker = " [–¥–ª—è —Ç–µ—Ä–∞–ø–∏–∏]"
                if ":" in context:
                    context = context.split(":", 1)[1].strip()
            elif context.startswith("AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ–º–æ–≥–ª–∞"):
                therapy_marker = " [AI –ø–æ–º–æ–≥]"
                if ":" in context:
                    context = context.split(":", 1)[1].strip()
            
            # Extract meaningful conversation from formatted text
            if context.startswith("–°–æ–æ–±—â–µ–Ω–∏–µ 1:"):
                # This is a formatted conversation, extract the main content
                messages = []
                for line in context.split("\n"):
                    if line.startswith("–°–æ–æ–±—â–µ–Ω–∏–µ ") and ":" in line:
                        msg_content = line.split(":", 1)[1].strip()
                        if msg_content:
                            messages.append(msg_content)
                
                if messages:
                    # Show the first message as the main context, mention if there are more
                    context = messages[0]
                    if len(messages) > 1:
                        context += f" [–∏ –µ—â—ë {len(messages)-1} —Å–æ–æ–±—â.]"
            
            # Limit context length for readability
            if len(context) > 120:
                context = context[:120] + "..."
            
            # Create formatted entry
            analysis_text += f"‚Ä¢ {date_str}, {emotion_name}: {context}{therapy_marker}\n"
        
        analysis_text += "\n"
    
    # Show simple diary entries
    if simple_diary_entries:
        analysis_text += "**–ë—ã—Å—Ç—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —ç–º–æ—Ü–∏–π:**\n"
        for entry in simple_diary_entries:
            # Format date and time
            date_str = entry.created_at.strftime("%d.%m.%Y, %H:%M")
            
            # Get emotion name and option
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state) if entry.state else "—ç–º–æ—Ü–∏—è"
            
            # Try to get specific option description
            option_text = ""
            if entry.state and entry.option and entry.option.startswith('option_'):
                try:
                    option_num = int(entry.option.split('_')[1])
                    option_description = OPTION_MAPPING.get(entry.state, {}).get(option_num, "")
                    if option_description:
                        option_text = f" ({option_description})"
                except (ValueError, IndexError):
                    pass
            
            # Create formatted entry
            analysis_text += f"‚Ä¢ {date_str}, {emotion_name}{option_text}\n"
        
        analysis_text += "\n"
    
    # Show message if no entries at all
    if not entries_with_context and not simple_diary_entries:
        analysis_text += "–ó–∞–ø–∏—Å–∏ —ç–º–æ—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n\n"
    

    
    # Add positive moments section - including both emotion entries and weekly reflections
    positive_entries = [e for e in emotion_entries if e.emotion_type == "positive"]
    
    # Get weekly reflections from the same period
    session = get_session()
    try:
        user = session.query(User).filter(User.telegram_id == callback.from_user.id).first()
        weekly_reflections = []
        if user:
            start_datetime = datetime.now() - timedelta(days=period_days)
            weekly_reflections = session.query(WeeklyReflection).filter(
                WeeklyReflection.user_id == user.id,
                WeeklyReflection.created_at >= start_datetime
            ).order_by(WeeklyReflection.created_at.desc()).all()
    finally:
        close_session(session)
    
    if positive_entries or weekly_reflections:
        analysis_text += f"\nüòä **–†–∞–¥–æ—Å—Ç–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:**\n"
        
        # Add positive emotion entries
        for entry in positive_entries[-3:]:  # Last 3 positive entries
            time_str = entry.created_at.strftime("%d.%m %H:%M")
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state) if entry.state else "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è —ç–º–æ—Ü–∏—è"
            analysis_text += f"‚Ä¢ {time_str}: {emotion_name}\n"
        
        # Add weekly reflection moments
        for reflection in weekly_reflections:
            reflection_date = reflection.created_at.strftime("%d.%m")
            analysis_text += f"\n**–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–∞—è —Ä–µ—Ñ–ª–µ–∫—Å–∏—è ({reflection_date}):**\n"
            
            if reflection.smile_moment:
                analysis_text += f"‚Ä¢ –ú–æ–º–µ–Ω—Ç —É–ª—ã–±–∫–∏: {reflection.smile_moment[:100]}{'...' if len(reflection.smile_moment) > 100 else ''}\n"
            
            if reflection.kindness:
                analysis_text += f"‚Ä¢ –î–æ–±—Ä–æ—Ç–∞: {reflection.kindness[:100]}{'...' if len(reflection.kindness) > 100 else ''}\n"
            
            if reflection.peace_moment:
                analysis_text += f"‚Ä¢ –°–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ: {reflection.peace_moment[:100]}{'...' if len(reflection.peace_moment) > 100 else ''}\n"
            
            if reflection.new_discovery:
                analysis_text += f"‚Ä¢ –û—Ç–∫—Ä—ã—Ç–∏–µ: {reflection.new_discovery[:100]}{'...' if len(reflection.new_discovery) > 100 else ''}\n"
            
            if reflection.gratitude:
                analysis_text += f"‚Ä¢ –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å: {reflection.gratitude[:100]}{'...' if len(reflection.gratitude) > 100 else ''}\n"
    
    # Generate emotion charts even for short analysis
    try:
        # Generate emotion frequency charts
        chart_path = await create_emotion_charts(emotion_entries, start_date, end_date)
        
        if chart_path:
            # Send emotion frequency chart
            chart_file = FSInputFile(chart_path, filename=f"emotion_charts_{start_date}_{end_date}.png")
            await callback.message.answer_photo(
                chart_file,
                caption=f"üìä –ì—Ä–∞—Ñ–∏–∫–∏ —á–∞—Å—Ç–æ—Ç—ã —ç–º–æ—Ü–∏–π –∑–∞ –ø–µ—Ä–∏–æ–¥ {start_date} - {end_date}"
            )
            
            # Clean up chart file
            os.unlink(chart_path)
        
    except Exception as e:
        logger.error(f"Error generating charts: {e}")
    
    # Generate advice for most common negative emotion
    negative_entries = [e for e in emotion_entries if e.emotion_type == "negative"]
    if negative_entries:
        negative_states = [e.state for e in negative_entries if e.state]
        if negative_states:
            most_common_negative = Counter(negative_states).most_common(1)[0]
            await generate_advice_for_emotion(callback, analysis_text, most_common_negative[0], negative_entries)
            return
    
    # Send analysis without advice if no negative emotions
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main")]
    ])
    await callback.message.edit_text(analysis_text, reply_markup=keyboard, parse_mode="Markdown")

async def generate_advice_for_emotion(callback: types.CallbackQuery, analysis_text: str, 
                                    emotion_state: str, negative_entries: List[EmotionEntry]):
    """Generate AI advice for the most common negative emotion"""
    
    emotion_name = EMOTION_MAPPING.get(emotion_state, emotion_state)
    
    # Collect contexts for this emotion
    contexts = []
    for entry in negative_entries:
        if entry.state == emotion_state and entry.answer_text:
            contexts.append(entry.answer_text)
    
    context_text = " ".join(contexts[:3]) if contexts else ""
    
    prompt = f"""
    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —á–∞—Å—Ç–æ –∏—Å–ø—ã—Ç—ã–≤–∞–µ—Ç —ç–º–æ—Ü–∏—é: {emotion_name}
    –ö–æ–Ω—Ç–µ–∫—Å—Ç—ã, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —ç—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç: {context_text}
    
    –î–∞–π –∫—Ä–∞—Ç–∫–∏–π, –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–π —Å–æ–≤–µ—Ç (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ø–æ —Ä–∞–±–æ—Ç–µ —Å —ç—Ç–æ–π —ç–º–æ—Ü–∏–µ–π, 
    —É—á–∏—Ç—ã–≤–∞—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã. –ë—É–¥—å —ç–º–ø–∞—Ç–∏—á–Ω—ã–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º.
    –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π markdown.
    """
    
    try:
        response = await asyncio.to_thread(
            client.models.generate_content,
            model="gemini-2.0-flash",
            contents=[prompt]
        )
        advice = response.text if hasattr(response, 'text') else str(response)
    except Exception as e:
        logger.error(f"Error generating advice: {e}")
        advice = f"–†–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —ç–º–æ—Ü–∏—é '{emotion_name}' –∏ –ø–æ–¥—É–º–∞—Ç—å –æ —Ç–æ–º, —á—Ç–æ –µ—ë –≤—ã–∑—ã–≤–∞–µ—Ç. –Ω–µ –∏—Å–æ–ø–ª—å–∑—É–π markdown"
    
    analysis_text += f"\nüí° –°–æ–≤–µ—Ç –ø–æ —Ä–∞–±–æ—Ç–µ —Å —ç–º–æ—Ü–∏–µ–π '{emotion_name}':\n{advice}"
    
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main")]
    ])
    await callback.message.edit_text(analysis_text, reply_markup=keyboard, parse_mode="Markdown")



async def generate_pdf_report(callback: types.CallbackQuery, state: FSMContext, 
                            emotion_entries: List[EmotionEntry], period_days: int):
    """Generate PDF report for longer periods"""
    
    await callback.message.edit_text("üìÑ –ì–µ–Ω–µ—Ä–∏—Ä—É—é PDF-–æ—Ç—á–µ—Ç... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.")
    
    start_date = (datetime.now() - timedelta(days=period_days)).strftime("%d.%m.%Y")
    end_date = datetime.now().strftime("%d.%m.%Y")
    
    # Analyze emotions for the report
    emotion_states = [entry.state for entry in emotion_entries if entry.state]
    emotion_counter = Counter(emotion_states)
    
    positive_entries = [e for e in emotion_entries if e.emotion_type == "positive"]
    negative_entries = [e for e in emotion_entries if e.emotion_type == "negative"]
    
    # Generate therapy topics with AI
    therapy_topics = []
    if negative_entries:
        contexts = [e.answer_text for e in negative_entries if e.answer_text and len(e.answer_text) > 20]
        if contexts:
            therapy_topics = await generate_therapy_topics_text(contexts[:5])
    
    if not therapy_topics:
        therapy_topics = [
            "–†–∞–±–æ—Ç–∞ —Å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ü–∏–µ–π",
            "–†–∞–∑–≤–∏—Ç–∏–µ –Ω–∞–≤—ã–∫–æ–≤ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–∞", 
            "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–µ—Å—Å–æ–º"
        ]
    
    # Create emotion charts and collect their paths to embed into PDF later
    chart_paths = []
    try:
        # Generate emotion frequency charts
        chart_path = await create_emotion_charts(emotion_entries, start_date, end_date)
        
        if chart_path:
            chart_paths.append(chart_path)
        
    except Exception as e:
        logger.error(f"Error generating charts: {e}")
    
    # Create PDF
    try:
        pdf_path = await create_pdf_report(
            start_date, end_date, period_days, emotion_entries, 
            positive_entries, negative_entries, emotion_counter, therapy_topics, chart_paths
        )
        
        # Send PDF file
        pdf_file = FSInputFile(pdf_path, filename=f"emotion_report_{start_date}_{end_date}.pdf")
        await callback.message.answer_document(
            pdf_file,
            caption=f"üìä –û—Ç—á–µ—Ç –ø–æ —ç–º–æ—Ü–∏—è–º –∑–∞ –ø–µ—Ä–∏–æ–¥ {start_date} - {end_date}"
        )
        
        # Send button to return to main menu
        keyboard = InlineKeyboardMarkup(inline_keyboard=[
            [InlineKeyboardButton(text="–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main")]
        ])
        await callback.message.answer("–û—Ç—á–µ—Ç –≥–æ—Ç–æ–≤! üìÑ", reply_markup=keyboard)
        
        # Clean up temporary file
        os.unlink(pdf_path)
        # Remove generated chart images after they are embedded
        for p in chart_paths:
            try:
                os.unlink(p)
            except Exception:
                pass
        
    except Exception as e:
        logger.error(f"Error generating PDF: {e}")
        # Fallback to text report
        await generate_text_report(callback, start_date, end_date, period_days, 
                                 emotion_entries, positive_entries, negative_entries, 
                                 emotion_counter, therapy_topics)

def transliterate_russian(text: str) -> str:
    """Convert Russian text to Latin transliteration for PDF compatibility"""
    russian_to_latin = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
        '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya',
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'Yo',
        '–ñ': 'Zh', '–ó': 'Z', '–ò': 'I', '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M',
        '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T', '–£': 'U',
        '–§': 'F', '–•': 'H', '–¶': 'Ts', '–ß': 'Ch', '–®': 'Sh', '–©': 'Sch',
        '–™': '', '–´': 'Y', '–¨': '', '–≠': 'E', '–Æ': 'Yu', '–Ø': 'Ya'
    }
    
    result = ""
    for char in text:
        result += russian_to_latin.get(char, char)
    return result

def setup_russian_fonts():
    """Download and register DejaVu fonts for Russian text support"""
    try:
        # First, try to find system fonts that support Russian
        import platform
        system = platform.system()
        
        # Try to register system fonts first
        system_fonts_registered = False
        
        if system == "Darwin":  # macOS
            # Try common macOS fonts that support Cyrillic
            macos_fonts = [
                "/System/Library/Fonts/Helvetica.ttc",
                "/Library/Fonts/Arial.ttf",
                "/System/Library/Fonts/Times.ttc"
            ]
            for font_path in macos_fonts:
                if os.path.exists(font_path):
                    try:
                        pdfmetrics.registerFont(TTFont('RussianFont', font_path))
                        pdfmetrics.registerFont(TTFont('RussianFont-Bold', font_path))
                        system_fonts_registered = True
                        logger.info(f"Registered system font: {font_path}")
                        break
                    except:
                        continue
        
        elif system == "Linux":
            # Try common Linux fonts
            linux_fonts = [
                "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
                "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
                "/usr/share/fonts/TTF/DejaVuSans.ttf"
            ]
            for font_path in linux_fonts:
                if os.path.exists(font_path):
                    try:
                        pdfmetrics.registerFont(TTFont('RussianFont', font_path))
                        bold_path = font_path.replace('Regular', 'Bold').replace('.ttf', '-Bold.ttf')
                        if os.path.exists(bold_path):
                            pdfmetrics.registerFont(TTFont('RussianFont-Bold', bold_path))
                        else:
                            pdfmetrics.registerFont(TTFont('RussianFont-Bold', font_path))
                        system_fonts_registered = True
                        logger.info(f"Registered system font: {font_path}")
                        break
                    except:
                        continue
        
        elif system == "Windows":
            # Try common Windows fonts
            windows_fonts = [
                "C:/Windows/Fonts/arial.ttf",
                "C:/Windows/Fonts/calibri.ttf",
                "C:/Windows/Fonts/tahoma.ttf"
            ]
            for font_path in windows_fonts:
                if os.path.exists(font_path):
                    try:
                        pdfmetrics.registerFont(TTFont('RussianFont', font_path))
                        bold_path = font_path.replace('.ttf', 'b.ttf')
                        if os.path.exists(bold_path):
                            pdfmetrics.registerFont(TTFont('RussianFont-Bold', bold_path))
                        else:
                            pdfmetrics.registerFont(TTFont('RussianFont-Bold', font_path))
                        system_fonts_registered = True
                        logger.info(f"Registered system font: {font_path}")
                        break
                    except:
                        continue
        
        if system_fonts_registered:
            return True
        
        # If system fonts failed, try to download DejaVu fonts
        # Create fonts directory if it doesn't exist
        fonts_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'fonts')
        os.makedirs(fonts_dir, exist_ok=True)
        
        # Check if fonts already exist
        dejavu_path = os.path.join(fonts_dir, 'DejaVuSans.ttf')
        dejavu_bold_path = os.path.join(fonts_dir, 'DejaVuSans-Bold.ttf')
        
        if os.path.exists(dejavu_path) and os.path.exists(dejavu_bold_path):
            # Fonts already downloaded, just register them
            pdfmetrics.registerFont(TTFont('RussianFont', dejavu_path))
            pdfmetrics.registerFont(TTFont('RussianFont-Bold', dejavu_bold_path))
            logger.info("Using existing DejaVu fonts")
            return True
        
        # Try to download fonts with SSL context handling
        import ssl
        import urllib.request
        
        # Create SSL context that doesn't verify certificates (for corporate networks)
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        
        # Font URLs and filenames
        fonts = {
            'DejaVuSans.ttf': 'https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/DejaVuSans.ttf',
            'DejaVuSans-Bold.ttf': 'https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/DejaVuSans-Bold.ttf'
        }
        
        # Download fonts if they don't exist
        for filename, url in fonts.items():
            font_path = os.path.join(fonts_dir, filename)
            if not os.path.exists(font_path):
                logger.info(f"Downloading font: {filename}")
                request = urllib.request.Request(url)
                with urllib.request.urlopen(request, context=ssl_context) as response:
                    with open(font_path, 'wb') as f:
                        f.write(response.read())
        
        # Register fonts with ReportLab
        if os.path.exists(dejavu_path):
            pdfmetrics.registerFont(TTFont('RussianFont', dejavu_path))
        if os.path.exists(dejavu_bold_path):
            pdfmetrics.registerFont(TTFont('RussianFont-Bold', dejavu_bold_path))
            
        return True
    except Exception as e:
        logger.error(f"Error setting up Russian fonts: {e}")
        # Try to register a basic font that might work
        try:
            # Use built-in fonts as last resort
            pdfmetrics.registerFont(TTFont('RussianFont', 'Helvetica'))
            pdfmetrics.registerFont(TTFont('RussianFont-Bold', 'Helvetica-Bold'))
            logger.info("Using fallback Helvetica fonts")
            return False  # Return False to indicate limited support
        except:
            return False

async def create_pdf_report(start_date: str, end_date: str, period_days: int,
                          emotion_entries: List[EmotionEntry], positive_entries: List[EmotionEntry],
                          negative_entries: List[EmotionEntry], emotion_counter: Counter,
                          therapy_topics: List[str], chart_paths: List[str]) -> str:
    """Create PDF report and return file path using ReportLab with transliteration.
    chart_paths: list of image file paths to embed into the PDF (emotion charts)."""
    
    # Setup Russian fonts
    fonts_available = setup_russian_fonts()
    
    # Create temporary file
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
        pdf_path = tmp_file.name
    
    # Create PDF document
    doc = SimpleDocTemplate(pdf_path, pagesize=A4)
    styles = getSampleStyleSheet()
    story = []
    
    # Define custom styles with Russian font support
    if fonts_available:
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=18,
            spaceAfter=30,
            alignment=1,  # Center alignment
            fontName='RussianFont-Bold'
        )
        
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontSize=14,
            spaceAfter=12,
            fontName='RussianFont-Bold'
        )
        
        normal_style = ParagraphStyle(
            'CustomNormal',
            parent=styles['Normal'],
            fontSize=10,
            fontName='RussianFont'
        )
    else:
        # Fallback to default styles if fonts are not available
        title_style = styles['Heading1']
        heading_style = styles['Heading2']
        normal_style = styles['Normal']
    
    # Title
    story.append(Paragraph("–û—Ç—á–µ—Ç –ø–æ —ç–º–æ—Ü–∏—è–º", title_style))
    story.append(Paragraph(f"–ü–µ—Ä–∏–æ–¥: {start_date} - {end_date}", normal_style))
    story.append(Spacer(1, 20))
    
    # Statistics section (text instead of table)
    story.append(Paragraph("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", heading_style))
    stats_text = (
        f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(emotion_entries)}<br/>"
        f"–ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —ç–º–æ—Ü–∏–π: {len(positive_entries)}<br/>"
        f"–ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —ç–º–æ—Ü–∏–π: {len(negative_entries)}<br/>"
        f"–î–Ω–µ–π —Å –∑–∞–ø–∏—Å—è–º–∏: {len(set(e.created_at.date() for e in emotion_entries))}"
    )
    story.append(Paragraph(stats_text, normal_style))
    story.append(Spacer(1, 20))

    # Embed emotion charts images while preserving aspect ratio (fit to page width)
    if chart_paths:
        story.append(Paragraph("–ì—Ä–∞—Ñ–∏–∫–∏ —ç–º–æ—Ü–∏–π", heading_style))
        max_width = doc.width  # available drawing width inside page margins (in points)
        for img_path in chart_paths:
            try:
                # Determine original image aspect ratio
                with PILImage.open(img_path) as _pil_img:
                    img_w_px, img_h_px = _pil_img.size
                aspect = img_h_px / img_w_px if img_w_px else 0.75

                display_width = max_width
                display_height = display_width * aspect

                img = RLImage(img_path, width=display_width, height=display_height)
                story.append(img)
                story.append(Spacer(1, 15))
            except Exception as e:
                logger.error(f"Error embedding chart {img_path} into PDF: {e}")
    story.append(Spacer(1, 10))
    
    # Top emotions (bullet list instead of table)
    if emotion_counter:
        story.append(Paragraph("–¢–æ–ø-3 —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —ç–º–æ—Ü–∏–∏", heading_style))
        for state, count in emotion_counter.most_common(3):
            emotion_name = EMOTION_MAPPING.get(state, state)
            story.append(Paragraph(f"‚Ä¢ {emotion_name}: {count}", normal_style))
        story.append(Spacer(1, 20))
    
    # Key moments analysis section
    story.append(Paragraph("–ö—Ä–∞—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤", heading_style))
    
    # Sort all entries chronologically
    all_entries = sorted(emotion_entries, key=lambda x: x.created_at)
    
    # Separate entries into those with detailed context and simple diary entries
    entries_with_context = []
    simple_diary_entries = []
    
    for entry in all_entries:
        if entry.answer_text and entry.answer_text.strip():
            if entry.answer_text == "Emotion recorded from diary":
                # This is a simple emotion diary entry without detailed context
                simple_diary_entries.append(entry)
            elif entry.answer_text not in ["Marked for therapy work:"]:
                # This has actual user context/dialog
                entries_with_context.append(entry)
    
    # Show entries with detailed context first
    if entries_with_context:
        story.append(Paragraph("–ü–æ–¥—Ä–æ–±–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:", normal_style))
        for entry in entries_with_context:
            # Format date and time
            date_str = entry.created_at.strftime("%d.%m.%Y, %H:%M")
            
            # Get emotion name
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state) if entry.state else "—ç–º–æ—Ü–∏—è"
            
            # Get context/reason
            context = entry.answer_text.strip()
            
            # Handle special cases for marked therapy work
            if context.startswith("Marked for therapy work:"):
                context = context.replace("Marked for therapy work:", "").strip()
                if context.startswith("Marked for work (text not found in FSM)"):
                    continue  # Skip entries without proper context
            
            # Limit context length for readability
            if len(context) > 150:
                context = context[:150] + "..."
            
            # Create formatted entry
            entry_text = f"{date_str}, {emotion_name}: {context}"
            story.append(Paragraph(f"‚Ä¢ {entry_text}", normal_style))
        
        story.append(Spacer(1, 10))
    
    # Show simple diary entries
    if simple_diary_entries:
        story.append(Paragraph("–ë—ã—Å—Ç—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —ç–º–æ—Ü–∏–π:", normal_style))
        for entry in simple_diary_entries:
            # Format date and time
            date_str = entry.created_at.strftime("%d.%m.%Y, %H:%M")
            
            # Get emotion name and option
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state) if entry.state else "—ç–º–æ—Ü–∏—è"
            
            # Try to get specific option description
            option_text = ""
            if entry.state and entry.option and entry.option.startswith('option_'):
                try:
                    option_num = int(entry.option.split('_')[1])
                    option_description = OPTION_MAPPING.get(entry.state, {}).get(option_num, "")
                    if option_description:
                        option_text = f" ({option_description})"
                except (ValueError, IndexError):
                    pass
            
            # Create formatted entry
            entry_text = f"{date_str}, {emotion_name}{option_text}"
            story.append(Paragraph(f"‚Ä¢ {entry_text}", normal_style))
        
        story.append(Spacer(1, 20))
    
    # Show message if no entries at all
    if not entries_with_context and not simple_diary_entries:
        story.append(Paragraph("–ó–∞–ø–∏—Å–∏ —ç–º–æ—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.", normal_style))
        story.append(Spacer(1, 20))
    
    # Positive moments - including weekly reflections
    session = get_session()
    try:
        user = None
        weekly_reflections = []
        # Get user_id from emotion_entries if available
        if emotion_entries:
            user = session.query(User).filter(User.id == emotion_entries[0].user_id).first()
        
        if user:
            start_datetime = datetime.strptime(start_date, "%d.%m.%Y")
            end_datetime = datetime.strptime(end_date, "%d.%m.%Y")
            weekly_reflections = session.query(WeeklyReflection).filter(
                WeeklyReflection.user_id == user.id,
                WeeklyReflection.created_at >= start_datetime,
                WeeklyReflection.created_at <= end_datetime
            ).order_by(WeeklyReflection.created_at.desc()).all()
    finally:
        close_session(session)
    
    if positive_entries or weekly_reflections:
        story.append(Paragraph("–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã", heading_style))
        
        # Add positive emotion entries
        for entry in positive_entries[-5:]:  # Last 5 positive entries
            time_str = entry.created_at.strftime("%d.%m %H:%M")
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state) if entry.state else "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è —ç–º–æ—Ü–∏—è"
            story.append(Paragraph(f"‚Ä¢ {time_str}: {emotion_name}", normal_style))
        
        # Add weekly reflection moments
        for reflection in weekly_reflections:
            reflection_date = reflection.created_at.strftime("%d.%m")
            story.append(Paragraph(f"–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–∞—è —Ä–µ—Ñ–ª–µ–∫—Å–∏—è ({reflection_date}):", normal_style))
            
            if reflection.smile_moment:
                story.append(Paragraph(f"  ‚Ä¢ –ú–æ–º–µ–Ω—Ç —É–ª—ã–±–∫–∏: {reflection.smile_moment}", normal_style))
            
            if reflection.kindness:
                story.append(Paragraph(f"  ‚Ä¢ –î–æ–±—Ä–æ—Ç–∞: {reflection.kindness}", normal_style))
            
            if reflection.peace_moment:
                story.append(Paragraph(f"  ‚Ä¢ –°–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ: {reflection.peace_moment}", normal_style))
            
            if reflection.new_discovery:
                story.append(Paragraph(f"  ‚Ä¢ –û—Ç–∫—Ä—ã—Ç–∏–µ: {reflection.new_discovery}", normal_style))
            
            if reflection.gratitude:
                story.append(Paragraph(f"  ‚Ä¢ –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å: {reflection.gratitude}", normal_style))
        
        story.append(Spacer(1, 20))
    
    # Negative emotions analysis
    if negative_entries:
        negative_states = [e.state for e in negative_entries if e.state]
        if negative_states:
            negative_counter = Counter(negative_states)
            story.append(Paragraph("–î–µ—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —ç–º–æ—Ü–∏–∏ –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏", heading_style))
            for i, (state, count) in enumerate(negative_counter.most_common(3), 1):
                emotion_name = EMOTION_MAPPING.get(state, state)
                story.append(Paragraph(f"{i}. {emotion_name} ({count} —Ä–∞–∑)", normal_style))
            story.append(Paragraph("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å —ç—Ç–∏ —ç–º–æ—Ü–∏–∏ —Å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º.", normal_style))
            story.append(Spacer(1, 20))
    
    # Therapy topics
    story.append(Paragraph("–¢–µ–º—ã –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏ —Å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º", heading_style))
    for topic in therapy_topics:
        story.append(Paragraph(f"‚Ä¢ {topic}", normal_style))
    story.append(Spacer(1, 20))
    
    # Praise section
    story.append(Paragraph("–ü–æ—Ö–≤–∞–ª–∞", heading_style))
    praise_text = f"–û—Ç–ª–∏—á–Ω–æ! –¢—ã –≤–µ–¥–µ—à—å –¥–Ω–µ–≤–Ω–∏–∫ —ç–º–æ—Ü–∏–π —É–∂–µ {period_days} –¥–Ω–µ–π. " \
                  "–≠—Ç–æ –≤–∞–∂–Ω—ã–π —à–∞–≥ –∫ –ª—É—á—à–µ–º—É –ø–æ–Ω–∏–º–∞–Ω–∏—é —Å–µ–±—è –∏ —Å–≤–æ–∏—Ö —ç–º–æ—Ü–∏–π. –ü—Ä–æ–¥–æ–ª–∂–∞–π –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ!"
    story.append(Paragraph(praise_text, normal_style))
    
    # Build PDF
    doc.build(story)
    return pdf_path

async def generate_therapy_topics_text(contexts: List[str]) -> List[str]:
    """Generate therapy topics based on emotion contexts using AI"""
    
    if not contexts:
        return [
            "–†–∞–±–æ—Ç–∞ —Å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ü–∏–µ–π",
            "–†–∞–∑–≤–∏—Ç–∏–µ –Ω–∞–≤—ã–∫–æ–≤ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–∞", 
            "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–µ—Å—Å–æ–º"
        ]
    
    # Clean and extract meaningful content from contexts
    cleaned_contexts = []
    for context in contexts:
        if not context or not context.strip():
            continue
            
        cleaned_context = context.strip()
        
        # Remove therapy work markers
        if cleaned_context.startswith("Marked for therapy work:"):
            cleaned_context = cleaned_context.replace("Marked for therapy work:", "").strip()
        elif cleaned_context.startswith("–û—Ç–º–µ—á–µ–Ω–æ –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏ —Å —Ç–µ—Ä–∞–ø–µ–≤—Ç–æ–º"):
            if ":" in cleaned_context:
                cleaned_context = cleaned_context.split(":", 1)[1].strip()
        
        # Extract main content from formatted conversations
        if cleaned_context.startswith("–°–æ–æ–±—â–µ–Ω–∏–µ 1:"):
            messages = []
            for line in cleaned_context.split("\n"):
                if line.startswith("–°–æ–æ–±—â–µ–Ω–∏–µ ") and ":" in line:
                    msg_content = line.split(":", 1)[1].strip()
                    if msg_content:
                        messages.append(msg_content)
            
            if messages:
                cleaned_context = " ".join(messages)
        
        if cleaned_context and len(cleaned_context) > 10:  # Skip very short contexts
            cleaned_contexts.append(cleaned_context)
    
    context_text = " ".join(cleaned_contexts) if cleaned_contexts else " ".join(contexts)
    prompt = f"""
    –ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
    {context_text}
    
    –ü—Ä–µ–¥–ª–æ–∂–∏ 3-5 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–µ–º –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º. 
    –¢–µ–º—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º–∏ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –Ω–∞ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º.
    –û—Ç–≤–µ—á–∞–π —Å–ø–∏—Å–∫–æ–º, –∫–∞–∂–¥–∞—è —Ç–µ–º–∞ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏, –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π markdown.
    """
    
    try:
        response = await asyncio.to_thread(
            client.models.generate_content,
            model="gemini-2.0-flash",
            contents=[prompt]
        )
        topics_text = response.text if hasattr(response, 'text') else str(response)
        topics = [topic.strip() for topic in topics_text.split('\n') if topic.strip()]
        return topics[:5] if topics else [
            "–†–∞–±–æ—Ç–∞ —Å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ü–∏–µ–π",
            "–†–∞–∑–≤–∏—Ç–∏–µ –Ω–∞–≤—ã–∫–æ–≤ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–∞", 
            "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–µ—Å—Å–æ–º"
        ]
    except Exception as e:
        logger.error(f"Error generating therapy topics: {e}")
        return [
            "–†–∞–±–æ—Ç–∞ —Å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ä–µ–≥—É–ª—è—Ü–∏–µ–π",
            "–†–∞–∑–≤–∏—Ç–∏–µ –Ω–∞–≤—ã–∫–æ–≤ —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–∞", 
            "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–µ—Å—Å–æ–º"
        ]

async def generate_text_report(callback: types.CallbackQuery, start_date: str, end_date: str,
                             period_days: int, emotion_entries: List[EmotionEntry],
                             positive_entries: List[EmotionEntry], negative_entries: List[EmotionEntry],
                             emotion_counter: Counter, therapy_topics: List[str]):
    """Generate text report as fallback"""
    
    report_text = f"üìä –û—Ç—á–µ—Ç –ø–æ —ç–º–æ—Ü–∏—è–º –∑–∞ –ø–µ—Ä–∏–æ–¥ {start_date} - {end_date}\n\n"
    
    report_text += f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
    report_text += f"‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(emotion_entries)}\n"
    report_text += f"‚Ä¢ –ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —ç–º–æ—Ü–∏–π: {len(positive_entries)}\n"
    report_text += f"‚Ä¢ –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —ç–º–æ—Ü–∏–π: {len(negative_entries)}\n\n"
    
    if emotion_counter:
        report_text += "üéØ –¢–æ–ø-3 —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —ç–º–æ—Ü–∏–∏:\n"
        for i, (state, count) in enumerate(emotion_counter.most_common(3), 1):
            emotion_name = EMOTION_MAPPING.get(state, state)
            report_text += f"{i}. {emotion_name} ({count} —Ä–∞–∑)\n"
        report_text += "\n"
    
    # Key moments analysis section
    report_text += "üìù –ö—Ä–∞—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤:\n"
    
    # Sort all entries chronologically
    all_entries = sorted(emotion_entries, key=lambda x: x.created_at)
    
    # Separate entries into those with detailed context and simple diary entries
    entries_with_context = []
    simple_diary_entries = []
    
    for entry in all_entries:
        if entry.answer_text and entry.answer_text.strip():
            if entry.answer_text == "Emotion recorded from diary":
                # This is a simple emotion diary entry without detailed context
                simple_diary_entries.append(entry)
            elif entry.answer_text.startswith("Marked for therapy work:") or entry.answer_text.startswith("–û—Ç–º–µ—á–µ–Ω–æ –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏ —Å —Ç–µ—Ä–∞–ø–µ–≤—Ç–æ–º"):
                # This is marked for therapy work but might have context
                entries_with_context.append(entry)
            elif entry.answer_text.startswith("AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ–º–æ–≥–ª–∞"):
                therapy_marker = " [AI –ø–æ–º–æ–≥]"
                if ":" in entry.answer_text:
                    context = entry.answer_text.split(":", 1)[1].strip()
                entries_with_context.append(entry)
            elif entry.answer_text not in ["Marked for therapy work:"]:
                # This has actual user context/dialog
                entries_with_context.append(entry)
    
    # Show entries with detailed context first
    if entries_with_context:
        report_text += "**–ü–æ–¥—Ä–æ–±–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º:**\n"
        for entry in entries_with_context:
            # Format date and time
            date_str = entry.created_at.strftime("%d.%m.%Y, %H:%M")
            
            # Get emotion name
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state) if entry.state else "—ç–º–æ—Ü–∏—è"
            
            # Get context/reason
            context = entry.answer_text.strip()
            
            # Handle special cases for marked therapy work
            therapy_marker = ""
            if context.startswith("Marked for therapy work:"):
                therapy_marker = " [–¥–ª—è —Ç–µ—Ä–∞–ø–∏–∏]"
                context = context.replace("Marked for therapy work:", "").strip()
                if context.startswith("Marked for work (text not found in FSM)"):
                    continue  # Skip entries without proper context
            elif context.startswith("–û—Ç–º–µ—á–µ–Ω–æ –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏ —Å —Ç–µ—Ä–∞–ø–µ–≤—Ç–æ–º"):
                therapy_marker = " [–¥–ª—è —Ç–µ—Ä–∞–ø–∏–∏]"
                if ":" in context:
                    context = context.split(":", 1)[1].strip()
            elif context.startswith("AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ–º–æ–≥–ª–∞"):
                therapy_marker = " [AI –ø–æ–º–æ–≥]"
                if ":" in context:
                    context = context.split(":", 1)[1].strip()
            
            # Extract meaningful conversation from formatted text
            if context.startswith("–°–æ–æ–±—â–µ–Ω–∏–µ 1:"):
                # This is a formatted conversation, extract the main content
                messages = []
                for line in context.split("\n"):
                    if line.startswith("–°–æ–æ–±—â–µ–Ω–∏–µ ") and ":" in line:
                        msg_content = line.split(":", 1)[1].strip()
                        if msg_content:
                            messages.append(msg_content)
                
                if messages:
                    # Show the first message as the main context, mention if there are more
                    context = messages[0]
                    if len(messages) > 1:
                        context += f" [–∏ –µ—â—ë {len(messages)-1} —Å–æ–æ–±—â.]"
            
            # Limit context length for readability
            if len(context) > 150:
                context = context[:150] + "..."
            
            # Create formatted entry
            report_text += f"‚Ä¢ {date_str}, {emotion_name}: {context}{therapy_marker}\n"
        
        report_text += "\n"
    
    # Show simple diary entries
    if simple_diary_entries:
        report_text += "**–ë—ã—Å—Ç—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —ç–º–æ—Ü–∏–π:**\n"
        for entry in simple_diary_entries:
            # Format date and time
            date_str = entry.created_at.strftime("%d.%m.%Y, %H:%M")
            
            # Get emotion name and option
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state) if entry.state else "—ç–º–æ—Ü–∏—è"
            
            # Try to get specific option description
            option_text = ""
            if entry.state and entry.option and entry.option.startswith('option_'):
                try:
                    option_num = int(entry.option.split('_')[1])
                    option_description = OPTION_MAPPING.get(entry.state, {}).get(option_num, "")
                    if option_description:
                        option_text = f" ({option_description})"
                except (ValueError, IndexError):
                    pass
            
            # Create formatted entry
            report_text += f"‚Ä¢ {date_str}, {emotion_name}{option_text}\n"
        
        report_text += "\n"
    
    # Show message if no entries at all
    if not entries_with_context and not simple_diary_entries:
        report_text += "–ó–∞–ø–∏—Å–∏ —ç–º–æ—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n\n"
    
    # Positive moments - including weekly reflections
    session = get_session()
    try:
        user = session.query(User).filter(User.telegram_id == callback.from_user.id).first()
        weekly_reflections = []
        if user:
            start_datetime = datetime.strptime(start_date, "%d.%m.%Y")
            end_datetime = datetime.strptime(end_date, "%d.%m.%Y")
            weekly_reflections = session.query(WeeklyReflection).filter(
                WeeklyReflection.user_id == user.id,
                WeeklyReflection.created_at >= start_datetime,
                WeeklyReflection.created_at <= end_datetime
            ).order_by(WeeklyReflection.created_at.desc()).all()
    finally:
        close_session(session)
    
    if positive_entries or weekly_reflections:
        report_text += "üòä –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:\n"
        
        # Add positive emotion entries
        for entry in positive_entries[-5:]:  # Last 5 positive entries
            time_str = entry.created_at.strftime("%d.%m %H:%M")
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state) if entry.state else "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è —ç–º–æ—Ü–∏—è"
            report_text += f"‚Ä¢ {time_str}: {emotion_name}\n"
        
        # Add weekly reflection moments
        for reflection in weekly_reflections:
            reflection_date = reflection.created_at.strftime("%d.%m")
            report_text += f"\n–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–∞—è —Ä–µ—Ñ–ª–µ–∫—Å–∏—è ({reflection_date}):\n"
            
            if reflection.smile_moment:
                report_text += f"‚Ä¢ –ú–æ–º–µ–Ω—Ç —É–ª—ã–±–∫–∏: {reflection.smile_moment[:100]}{'...' if len(reflection.smile_moment) > 100 else ''}\n"
            
            if reflection.kindness:
                report_text += f"‚Ä¢ –î–æ–±—Ä–æ—Ç–∞: {reflection.kindness[:100]}{'...' if len(reflection.kindness) > 100 else ''}\n"
            
            if reflection.peace_moment:
                report_text += f"‚Ä¢ –°–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ: {reflection.peace_moment[:100]}{'...' if len(reflection.peace_moment) > 100 else ''}\n"
            
            if reflection.new_discovery:
                report_text += f"‚Ä¢ –û—Ç–∫—Ä—ã—Ç–∏–µ: {reflection.new_discovery[:100]}{'...' if len(reflection.new_discovery) > 100 else ''}\n"
            
            if reflection.gratitude:
                report_text += f"‚Ä¢ –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å: {reflection.gratitude[:100]}{'...' if len(reflection.gratitude) > 100 else ''}\n"
        
        report_text += "\n"
    
    # Negative patterns analysis
    if negative_entries:
        negative_states = [e.state for e in negative_entries if e.state]
        if negative_states:
            negative_counter = Counter(negative_states)
            report_text += "‚ö†Ô∏è –¢–æ–ø-3 –¥–µ—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —ç–º–æ—Ü–∏–∏ –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏:\n"
            for i, (state, count) in enumerate(negative_counter.most_common(3), 1):
                emotion_name = EMOTION_MAPPING.get(state, state)
                report_text += f"{i}. {emotion_name} ({count} —Ä–∞–∑)\n"
            report_text += "\n–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å —ç—Ç–∏ —ç–º–æ—Ü–∏–∏ —Å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º.\n\n"
    
    # Topics for therapy
    report_text += "üéØ –¢–µ–º—ã –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏ —Å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º:\n"
    for topic in therapy_topics:
        report_text += f"‚Ä¢ {topic}\n"
    report_text += "\n"
    
    # Praise
    report_text += "üåü –ü–æ—Ö–≤–∞–ª–∞:\n"
    report_text += f"–û—Ç–ª–∏—á–Ω–æ! –¢—ã –≤–µ–¥–µ—à—å –¥–Ω–µ–≤–Ω–∏–∫ —ç–º–æ—Ü–∏–π —É–∂–µ {period_days} –¥–Ω–µ–π. "
    report_text += "–≠—Ç–æ –≤–∞–∂–Ω—ã–π —à–∞–≥ –∫ –ª—É—á—à–µ–º—É –ø–æ–Ω–∏–º–∞–Ω–∏—é —Å–µ–±—è –∏ —Å–≤–æ–∏—Ö —ç–º–æ—Ü–∏–π. –ü—Ä–æ–¥–æ–ª–∂–∞–π –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ!"
    
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main")]
    ])
    await callback.message.edit_text(report_text, reply_markup=keyboard, parse_mode="Markdown")

async def create_emotion_charts(emotion_entries: List[EmotionEntry], start_date: str, end_date: str) -> str:
    """Create emotion visualization charts and return the image path"""
    try:
        # Set up Russian font for matplotlib
        plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'Liberation Sans', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
        
        # Prepare data
        positive_emotions = {}
        negative_emotions = {}
        
        # Count emotions by type
        for entry in emotion_entries:
            if not entry.state:
                continue
                
            emotion_name = EMOTION_MAPPING.get(entry.state, entry.state)
            
            if entry.emotion_type == "positive":
                positive_emotions[emotion_name] = positive_emotions.get(emotion_name, 0) + 1
            elif entry.emotion_type == "negative":
                negative_emotions[emotion_name] = negative_emotions.get(emotion_name, 0) + 1
        
        # Prepare unified dictionary with all emotions
        all_emotions_counts = {}
        for key, val in positive_emotions.items():
            all_emotions_counts[key] = val
        for key, val in negative_emotions.items():
            all_emotions_counts[key] = val

        # Ensure every emotion has a key even if 0 so chart is always shown
        for state in EMOTION_MAPPING.values():
            all_emotions_counts.setdefault(state, 0)

        # Sort emotions in defined order (positive first then negative) according to mapping keys
        emotion_order = [EMOTION_MAPPING[k] for k in EMOTION_MAPPING]

        # Build one combined bar chart with all 10 —ç–º–æ—Ü–∏–π
        fig, ax = plt.subplots(figsize=(14, 7))
        fig.suptitle(f'–ß–∞—Å—Ç–æ—Ç–∞ –≤—ã–±–æ—Ä–∞ —ç–º–æ—Ü–∏–π\n–ü–µ—Ä–∏–æ–¥: {start_date} - {end_date}', fontsize=16, fontweight='bold')

        # Data for plotting
        counts = [all_emotions_counts[e] for e in emotion_order]
        x = np.arange(len(emotion_order))

        # Color bars by emotion valence
        bar_colors = []
        for emotion_name in emotion_order:
            orig_key = next(k for k, v in EMOTION_MAPPING.items() if v == emotion_name)
            bar_colors.append('#4CAF50' if orig_key.startswith('good') else '#FF9800')

        bars = ax.bar(x, counts, color=bar_colors, alpha=0.8)

        # Add value labels on top
        for rect, count in zip(bars, counts):
            height = rect.get_height()
            ax.annotate(f'{count}',
                        xy=(rect.get_x() + rect.get_width() / 2, height),
                        xytext=(0, 3),
                        textcoords="offset points",
                        ha='center', va='bottom', fontsize=9)

        # Axis formatting
        ax.set_xticks(x)
        ax.set_xticklabels(emotion_order, rotation=45, ha='right', fontsize=9)
        ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        ax.set_ylim(0, max(counts) + 1)
        plt.tight_layout(rect=[0, 0, 1, 0.95])
        
        # Save to temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_file:
            chart_path = tmp_file.name
        
        plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        return chart_path
        
    except Exception as e:
        logger.error(f"Error creating emotion charts: {e}")
        return None

 